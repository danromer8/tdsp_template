
markdown
Copiar
Editar
# üì¶ Despliegue de Modelos

## üèóÔ∏è Infraestructura

- **Nombre del modelo:** `Student Dropout Prediction`
- **Plataforma de despliegue:** `FastAPI` (desplegado localmente en entorno virtual)
- **Requisitos t√©cnicos:**
  - Entorno: Jupyter Notebook o entorno Python 3.10+ con venv
  - Lenguaje: Python 3.10+
  - Bibliotecas utilizadas:
    - `fastapi`
    - `uvicorn`
    - `scikit-learn`
    - `mlflow`
    - `joblib`
    - `pandas`
    - `gradio` (para interfaz de usuario)
    - `matplotlib`, `shap`, `seaborn` (para visualizaci√≥n e interpretabilidad)
    - `psutil`, `subprocess`, `signal`, `os`, `time` (para utilidades)
- **Requisitos de seguridad:**
  - Acceso local restringido (localhost)
  - Validaci√≥n de entrada con `Pydantic` en FastAPI
  - No se implement√≥ autenticaci√≥n ni control de acceso (opcional para producci√≥n)

---

## üß≠ Diagrama de Arquitectura

<div align="center">
<img src="https://drive.google.com/uc?export=view&id=1Q9IPtLlwXwvOz7lgJH0g-_aHqHl5KgqU" width="60%">
</div>

**Descripci√≥n:**  
El cliente (navegador o consumidor v√≠a API) accede al endpoint `/predict` de FastAPI.  
FastAPI recibe el JSON, lo convierte en `DataFrame`, consulta el modelo (cargado desde MLflow o archivo local), y retorna la predicci√≥n en formato JSON.  
La interfaz de usuario (Gradio) tambi√©n consume el endpoint local para realizar predicciones y mostrar interpretabilidad (SHAP).

---

## üíª C√≥digo de Despliegue

- **Script principal de la API:**  
  `scripts/deployment/api.py`  
  (o `main.py` si se utiliza en notebook para prototipo)

- **Ruta del modelo serializado:**  
  - Desde MLflow (ruta autom√°tica)  
  - O desde archivo local (ejemplo: `mlruns/.../model`, `model.joblib`)

- **Estructura esperada del input:**  
  JSON con una lista bajo el campo `"inputs"` que representa las observaciones a predecir.

- **Salida esperada del endpoint `/predict`:**
  ```json
  {
    "predictions": ["Dropout", "Graduate"],
    "prob_dropout": [0.75, 0.10]
  }


- **Inicio del servidor local:**
  ```python
  uvicorn scripts.deployment.api:app --reload
  ```
Acceso en: http://localhost:8000/docs


<div align="center">
<img src="https://drive.google.com/uc?export=view&id=1_9qIp9zYfwA5nhPbfjEa1jqsOYhYJbyE" width="80%">
</div>

<div align="center">
<img src="https://drive.google.com/uc?export=view&id=1yH8Jz0fVgZ9sw8qdjQDTsHbLpmnkTvZG" width="80%">
</div>

---

## üìÑ Documentaci√≥n del Despliegue

### üß© Instrucciones de instalaci√≥n

Instalar dependencias en el entorno virtual del proyecto:

`pip install -r requirements.txt`

O, si se usan m√≥dulos sueltos:

`pip install fastapi uvicorn scikit-learn mlflow joblib pandas gradio matplotlib shap seaborn`

### ‚öôÔ∏è Instrucciones de configuraci√≥n

No se requiere configuraci√≥n adicional.  
Si se consume modelo desde MLflow, verificar que el tracking server est√© corriendo con:  
`python scripts/training/mlflow_server.py`

### üöÄ Instrucciones de uso

1. Entrenar y guardar el modelo con MLflow o `joblib`.
2. Colocar el modelo accesible para la API (`mlruns/.../model` o `model.joblib`).
3. Iniciar la API ejecutando:  
   `uvicorn scripts.deployment.api:app --reload`
4. (Opcional) Iniciar la interfaz Gradio ejecutando:  
   `python scripts/deployment/app.py`
5. Consumir el endpoint `/predict` desde Swagger UI (`http://localhost:8000/docs`), la aplicaci√≥n Gradio (`http://localhost:7860`) o cualquier cliente REST, por ejemplo:

```python
import requests
resp = requests.post("http://localhost:8000/predict", json=sample)
print(resp.json())
```

### üîß Instrucciones de mantenimiento

- Si se actualiza el modelo, volver a guardar y reiniciar la API.
- Verificar que el puerto de `uvicorn` (por defecto 8000) est√© disponible y libre.
- Para ambientes productivos: agregar autenticaci√≥n, logging, y control de acceso seg√∫n los est√°ndares de la instituci√≥n.
- Documentar el versionado del modelo en MLflow para trazabilidad y reproducibilidad.
- Mantener actualizadas las dependencias en el archivo `requirements.txt`.
- Realizar pruebas peri√≥dicas a la API usando Swagger UI o scripts automatizados para asegurar su correcto funcionamiento.
- Monitorear el consumo de recursos del servidor, especialmente si se implementa en ambientes compartidos.

### üìù Observaciones

- El t√∫nel `ngrok` fue usado √∫nicamente para prototipos y acceso remoto temporal (Colab/Notebook).  
  En despliegues locales y productivos no es necesario.
- El despliegue actual est√° orientado a pruebas, demostraciones y validaci√≥n de resultados en ambiente controlado.
- La interfaz Gradio permite probar el modelo de manera visual y ver la explicabilidad de cada predicci√≥n mediante gr√°ficos SHAP.
- Para uso institucional o productivo se recomienda adicionar seguridad, versionado expl√≠cito de artefactos y un pipeline de CI/CD.

---

**Autores:**  
Daniel Enrique Romero Cantor  
Ivan Herney Hernandez  

